llm:
  provider: "openrouter"                          # openai | deepseek | glm | openrouter | local
  root_model: "deepseek/deepseek-r1-0528:free"   # reasoning model for root LM (depth 0)
  sub_model: "openai/gpt-oss-120b:free"           # cheaper model for sub-LM calls (depth 1+)
  api_key: "${OPENROUTER_API_KEY}"                # or set RLM_API_KEY env var
  # base_url: "https://openrouter.ai/api/v1"     # override for custom endpoints

search:
  provider: "tavily"              # tavily | brave | searxng
  api_key: "${TAVILY_API_KEY}"    # not needed for searxng
  # base_url: "http://localhost:8080"  # for self-hosted searxng

engine:
  max_recursion_depth: 3          # 1-10
  max_turns: 30                   # max code-execute-observe iterations
  max_sub_lm_calls: 50            # total sub_lm budget
  timeout_per_exec: 30            # seconds per code block execution
